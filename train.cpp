/******************************************************************************
 *  Copyright (c) 2026 The Transformer project authors . All Rights Reserved.
 *
 *  Please visit https://chensongpoixs.github.io for detail
 *
 *  Use of this source code is governed by a BSD-style license
 *  that can be found in the LICENSE file in the root of the source
 *  tree. An additional intellectual property rights grant can be found
 *  in the file PATENTS.  All contributing project authors may
 *  be found in the AUTHORS file in the root of the source tree.
 ******************************************************************************/
/*****************************************************************************
				   Author: chensong
				   date:  2026-01-01
 * è®­ç»ƒå®ç° (Training Implementation)
 * 
 * å®ç°å®Œæ•´çš„è®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬ï¼š
 * - run_epoch: è¿è¡Œä¸€ä¸ª epoch çš„è®­ç»ƒæˆ–éªŒè¯ï¼Œæ”¯æŒ bucket é‡‡æ ·
 * - train: ä¸»è®­ç»ƒå‡½æ•°ï¼ŒåŒ…å«è®­ç»ƒå¾ªç¯ã€éªŒè¯ã€æ¨¡å‹ä¿å­˜ç­‰
 * - evaluate: è¯„ä¼°å‡½æ•°ï¼Œä½¿ç”¨ beam search è§£ç å¹¶è®¡ç®— BLEU åˆ†æ•°
 * - save_config_file: ä¿å­˜è®­ç»ƒé…ç½®åˆ° config.yamlï¼ˆYOLOv5 é£æ ¼ï¼‰
 * 
 * è®­ç»ƒç‰¹æ€§ï¼š
 * - YOLOv5 é£æ ¼çš„è¿›åº¦æ˜¾ç¤ºå’Œæ—¥å¿—è¾“å‡º
 * - åŸºäºéªŒè¯æŸå¤±ä¿å­˜æœ€ä½³æ¨¡å‹
 * - æ”¯æŒ bucket é‡‡æ ·æé«˜è®­ç»ƒæ•ˆç‡
				   
				   
				   
				   
 è¾“èµ¢ä¸é‡è¦ï¼Œç­”æ¡ˆå¯¹ä½ ä»¬æœ‰ä»€ä¹ˆæ„ä¹‰æ‰é‡è¦ã€‚

 å…‰é˜´è€…ï¼Œç™¾ä»£ä¹‹è¿‡å®¢ä¹Ÿï¼Œå”¯æœ‰å¥‹åŠ›å¥”è·‘ï¼Œæ–¹èƒ½ç”Ÿé£èµ·æ—¶ï¼Œæ˜¯æ—¶ä»£é€ è‹±é›„ï¼Œè‹±é›„å­˜åœ¨äºæ—¶ä»£ã€‚æˆ–è®¸ä¸–äººé“ä½ è½»ç‹‚ï¼Œå¯ä½ æœ¬å°±å¹´å°‘å•Šã€‚ çœ‹æŠ¤å¥½ï¼Œè‡ªå·±çš„ç†æƒ³å’Œæ¿€æƒ…ã€‚


 æˆ‘å¯èƒ½ä¼šé‡åˆ°å¾ˆå¤šçš„äººï¼Œå¬ä»–ä»¬è®²å¥½2å¤šçš„æ•…äº‹ï¼Œæˆ‘æ¥å†™æˆæ•…äº‹æˆ–ç¼–æˆæ­Œï¼Œç”¨æˆ‘å­¦æ¥çš„å„ç§ä¹å™¨æ¼”å¥å®ƒã€‚
 ç„¶åè¿˜å¯èƒ½åœ¨ä¸€ä¸ªå›½å®¶é‡åˆ°ä¸€ä¸ªå¿ƒä»ªæˆ‘çš„å§‘å¨˜ï¼Œå¥¹å¯èƒ½ä¼šè¢«æˆ‘å¸…æ°”çš„å¤–è¡¨æ•è·ï¼Œåˆä¼šè¢«æˆ‘æ·±é‚ƒçš„å†…æ¶µå¸å¼•ï¼Œåœ¨æŸä¸ªä¸‹é›¨çš„å¤œæ™šï¼Œå¥¹ä¼šå…¨èº«æ·‹é€ç„¶åè¦åœ¨æˆ‘ç‹­å°çš„ä½å¤„æ¢èº«ä¸Šçš„æ¹¿è¡£æœã€‚
 3å°æ—¶å€™åå¥¹å‘Šè¯‰æˆ‘å¥¹å…¶å®æ˜¯è¿™ä¸ªå›½å®¶çš„å…¬ä¸»ï¼Œå¥¹æ„¿æ„å‘çˆ¶çš‡æ±‚å©šã€‚æˆ‘ä¸å¾—å·²å‘Šè¯‰å¥¹æˆ‘æ˜¯ç©¿è¶Šè€Œæ¥çš„ç”·ä¸»è§’ï¼Œæˆ‘å§‹ç»ˆè¦å›åˆ°è‡ªå·±çš„ä¸–ç•Œã€‚
 ç„¶åæˆ‘çš„èº«å½±æ…¢æ…¢æ¶ˆå¤±ï¼Œæˆ‘çœ‹åˆ°å¥¹çœ¼é‡Œçš„æ³ªæ°´ï¼Œå¿ƒé‡Œå´æ²¡æœ‰ä»»ä½•ç—›è‹¦ï¼Œæˆ‘æ‰çŸ¥é“ï¼ŒåŸæ¥æˆ‘çš„å¿ƒè¢«ä¸¢æ‰äº†ï¼Œæˆ‘æ¸¸å†å…¨ä¸–ç•Œçš„åŸå› ï¼Œå°±æ˜¯è¦æ‰¾å›è‡ªå·±çš„æœ¬å¿ƒã€‚
 äºæ˜¯æˆ‘å¼€å§‹æœ‰æ„å¯»æ‰¾å„ç§å„æ ·å¤±å»å¿ƒçš„äººï¼Œæˆ‘å˜æˆä¸€å—ç –å¤´ï¼Œä¸€é¢—æ ‘ï¼Œä¸€æ»´æ°´ï¼Œä¸€æœµç™½äº‘ï¼Œå»å¬å¤§å®¶ä¸ºä»€ä¹ˆä¼šå¤±å»è‡ªå·±çš„æœ¬å¿ƒã€‚
 æˆ‘å‘ç°ï¼Œåˆšå‡ºç”Ÿçš„å®å®ï¼Œæœ¬å¿ƒè¿˜åœ¨ï¼Œæ…¢æ…¢çš„ï¼Œä»–ä»¬çš„æœ¬å¿ƒå°±ä¼šæ¶ˆå¤±ï¼Œæ”¶åˆ°äº†å„ç§é»‘æš—ä¹‹å…‰çš„ä¾µèš€ã€‚
 ä»ä¸€æ¬¡äº‰è®ºï¼Œåˆ°å«‰å¦’å’Œæ‚²æ„¤ï¼Œè¿˜æœ‰å§”å±ˆå’Œç—›è‹¦ï¼Œæˆ‘çœ‹åˆ°ä¸€åªåªæ— å½¢çš„æ‰‹ï¼ŒæŠŠä»–ä»¬çš„æœ¬å¿ƒæ‰¯ç¢ï¼Œè’™è”½ï¼Œå·èµ°ï¼Œå†ä¹Ÿå›ä¸åˆ°ä¸»äººéƒ½èº«è¾¹ã€‚
 æˆ‘å«ä»–æœ¬å¿ƒçŒæ‰‹ã€‚ä»–å¯èƒ½æ˜¯å’Œå®‡å®™åŒåœ¨çš„çº§åˆ« ä½†æ˜¯æˆ‘å¹¶ä¸å®³æ€•ï¼Œæˆ‘ä»”ç»†å›å¿†è‡ªå·±å¹³æ·¡çš„ä¸€ç”Ÿ å¯»æ‰¾æœ¬å¿ƒçŒæ‰‹çš„ç—•è¿¹ã€‚
 æ²¿ç€è‡ªå·±çš„å›å¿†ï¼Œä¸€ä¸ªä¸ªçš„åœºæ™¯å¿½é—ªè€Œè¿‡ï¼Œæœ€åå‘ç°ï¼Œæˆ‘çš„æœ¬å¿ƒï¼Œåœ¨æˆ‘å†™ä»£ç çš„æ—¶å€™ï¼Œä¼šå›æ¥ã€‚
 å®‰é™ï¼Œæ·¡ç„¶ï¼Œä»£ç å°±æ˜¯æˆ‘çš„ä¸€åˆ‡ï¼Œå†™ä»£ç å°±æ˜¯æˆ‘æœ¬å¿ƒå›å½’çš„æœ€å¥½æ–¹å¼ï¼Œæˆ‘è¿˜æ²¡æ‰¾åˆ°æœ¬å¿ƒçŒæ‰‹ï¼Œä½†æˆ‘ç›¸ä¿¡ï¼Œé¡ºç€è¿™ä¸ªçº¿ç´¢ï¼Œæˆ‘ä¸€å®šèƒ½é¡ºè—¤æ‘¸ç“œï¼ŒæŠŠä»–æªå‡ºæ¥ã€‚

 ******************************************************************************/

#include "train.h"
#include "beam_search.h"
#include "multi_process_loader.h"
#include "data_cache.h"
#include "amp_scaler.h"
#include "bleu.h"
#include "tokenizer_wrapper.h"
#include "logger.h"
#include "gpu_profiler.h"
#include "cuda_stream_manager.h"
#include "resource_manager.h"
#include "json.hpp"
#include <iomanip>
#include <algorithm>
#include <random>
#include <filesystem>
#include <numeric>
#include <limits>
#include <sstream>
#include <utility>
#include <tuple>
#include <chrono>
#include <cmath>
#include <c10/cuda/CUDAGuard.h>
#include <c10/cuda/CUDAFunctions.h>
#include <cuda_runtime.h>
#include <fstream>
#include <ctime>
#include <future>
#include <thread>


namespace fs = std::filesystem;
using namespace logging;
using namespace std::chrono;
using json = nlohmann::json;

// ä»¿ç…§ Python tools/create_exp_folder.py çš„å®éªŒç›®å½•åˆ›å»ºé€»è¾‘
// è¿”å›: (exp_folder, weights_folder)
// æ”¯æŒ YOLOv5 é£æ ¼çš„ --project å’Œ --name å‚æ•°
static std::pair<std::string, std::string> create_exp_folder_cpp(
    const std::string& project,
    const std::string& name,
    bool exist_ok) {
    
    fs::path project_path(project);
    
    // ç¡®ä¿é¡¹ç›®ç›®å½•å­˜åœ¨
    std::error_code ec;
    fs::create_directories(project_path, ec);
    if (ec) {
        LOG_WARN("Failed to create project directory: " + project_path.string() + ", error: " + ec.message());
    }

    // é¦–å…ˆå°è¯• project/name
    fs::path exp_dir = project_path / name;
    if (!fs::exists(exp_dir) || exist_ok) {
        if (exist_ok && fs::exists(exp_dir)) {
            LOG_INFO("Experiment directory already exists, use existing directory: " + exp_dir.string());
        }
        fs::create_directories(exp_dir / "weights", ec);
        if (ec) {
            LOG_WARN("Failed to create weights directory: " + (exp_dir / "weights").string() + ", error: " + ec.message());
        }
        return {exp_dir.string(), (exp_dir / "weights").string()};
    }

    // å¦‚æœ name å·²å­˜åœ¨ä¸” exist_ok=falseï¼ŒæŒ‰ name1, name2, ... é€’å¢
    int exp_num = 1;
    while (true) {
        fs::path exp_dir_i = project_path / (name + std::to_string(exp_num));
        if (!fs::exists(exp_dir_i)) {
            fs::create_directories(exp_dir_i / "weights", ec);
            if (ec) {
                LOG_WARN("Failed to create weights directory: " + (exp_dir_i / "weights").string() + ", error: " + ec.message());
            }
            return {exp_dir_i.string(), (exp_dir_i / "weights").string()};
        }
        ++exp_num;
    }
}

/**
 * ä¿å­˜è®­ç»ƒé…ç½®æ–‡ä»¶ï¼ˆYOLOv5 é£æ ¼ï¼‰
 * @param config è®­ç»ƒé…ç½®
 * @param exp_folder å®éªŒæ–‡ä»¶å¤¹è·¯å¾„
 */
static void save_config_file(const TransformerConfig& config, const std::string& exp_folder) {
    // ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆä½¿ç”¨ config.yamlï¼‰
    std::string config_path = exp_folder + "/config.yaml";
    std::ofstream config_file(config_path);
    if (!config_file.is_open()) {
        LOG_WARN("Failed to save training config file: " + config_path);
        return;
    }
    
    // YOLOv5 é£æ ¼çš„ YAML æ ¼å¼ï¼Œå¸¦æ³¨é‡Šå’Œåˆ†ç»„
    config_file << "# Transformer Training Configuration\n";
    config_file << "# Generated automatically during training\n\n";
    
    // Train è®­ç»ƒé…ç½®
    config_file << "# Train\n";
    config_file << "epochs: " << config.epoch_num << "  # è®­ç»ƒè½®æ•°\n";
    config_file << "batch_size: " << config.batch_size << "  # æ‰¹æ¬¡å¤§å°\n";
    config_file << "lr: " << std::scientific << config.lr << "  # å­¦ä¹ ç‡\n";
    config_file << "workers: " << config.workers << "  # æ•°æ®åŠ è½½çº¿ç¨‹æ•°\n";
    config_file << "\n";
    
    // Model æ¨¡å‹é…ç½®
    config_file << "# Model\n";
    config_file << "d_model: " << config.d_model << "  # æ¨¡å‹ç»´åº¦\n";
    config_file << "n_heads: " << config.n_heads << "  # å¤šå¤´æ³¨æ„åŠ›å¤´æ•°\n";
    config_file << "n_layers: " << config.n_layers << "  # Transformerå±‚æ•°\n";
    config_file << "d_k: " << config.d_k << "  # æ¯ä¸ªå¤´çš„é”®å‘é‡ç»´åº¦\n";
    config_file << "d_v: " << config.d_v << "  # æ¯ä¸ªå¤´çš„å€¼å‘é‡ç»´åº¦\n";
    config_file << "d_ff: " << config.d_ff << "  # å‰é¦ˆç½‘ç»œéšè—å±‚ç»´åº¦\n";
    config_file << "dropout: " << std::fixed << std::setprecision(2) << config.dropout << "  # Dropoutç‡\n";
    config_file << "\n";
    
    // Vocabulary è¯æ±‡è¡¨é…ç½®
    config_file << "# Vocabulary\n";
    config_file << "src_vocab_size: " << config.src_vocab_size << "  # æºè¯­è¨€è¯æ±‡è¡¨å¤§å°\n";
    config_file << "tgt_vocab_size: " << config.tgt_vocab_size << "  # ç›®æ ‡è¯­è¨€è¯æ±‡è¡¨å¤§å°\n";
    config_file << "padding_idx: " << config.padding_idx << "  # Paddingæ ‡è®°ç´¢å¼•\n";
    config_file << "bos_idx: " << config.bos_idx << "  # å¼€å§‹ç¬¦ç´¢å¼•\n";
    config_file << "eos_idx: " << config.eos_idx << "  # ç»“æŸç¬¦ç´¢å¼•\n";
    config_file << "\n";
    
    // Decode è§£ç é…ç½®
    config_file << "# Decode\n";
    config_file << "max_len: " << config.max_len << "  # æœ€å¤§åºåˆ—é•¿åº¦\n";
    config_file << "beam_size: " << config.beam_size << "  # Beam Searchå¤§å°\n";
    config_file << "\n";
    
    // Data æ•°æ®è·¯å¾„é…ç½®
    config_file << "# Data\n";
    config_file << "data_dir: " << config.data_dir << "  # æ•°æ®ç›®å½•\n";
    config_file << "train: " << config.train_data_path << "  # è®­ç»ƒé›†è·¯å¾„\n";
    config_file << "val: " << config.dev_data_path << "  # éªŒè¯é›†è·¯å¾„\n";
    config_file << "test: " << config.test_data_path << "  # æµ‹è¯•é›†è·¯å¾„\n";
    config_file << "\n";
    
    // Tokenizer åˆ†è¯å™¨é…ç½®
    config_file << "# Tokenizer\n";
    config_file << "tokenizer_dir: " << config.tokenizer_dir << "  # åˆ†è¯å™¨ç›®å½•\n";
    config_file << "tokenizer_eng: " << config.tokenizer_eng << "  # è‹±æ–‡åˆ†è¯å™¨æ¨¡å‹è·¯å¾„\n";
    config_file << "tokenizer_chn: " << config.tokenizer_chn << "  # ä¸­æ–‡åˆ†è¯å™¨æ¨¡å‹è·¯å¾„\n";
    config_file << "\n";
    
    // Project é¡¹ç›®é…ç½®
    config_file << "# Project\n";
    config_file << "project: " << config.project << "  # é¡¹ç›®ç›®å½•\n";
    config_file << "name: " << config.name << "  # å®éªŒåç§°\n";
    config_file << "exist_ok: " << (config.exist_ok ? "true" : "false") << "  # æ˜¯å¦è¦†ç›–å·²å­˜åœ¨ç›®å½•\n";
    config_file << "\n";
    
    // Device è®¾å¤‡é…ç½®
    config_file << "# Device\n";
    config_file << "use_cuda: " << (config.use_cuda ? "true" : "false") << "  # æ˜¯å¦ä½¿ç”¨CUDA\n";
    config_file << "device_id: " << config.device_id << "  # GPUè®¾å¤‡ID\n";
    
    config_file.close();
    LOG_INFO("Training config saved to: " + config_path);
}


/**
 * YOLOv5 é£æ ¼çš„è¡¨æ ¼æ ¼å¼å®æ—¶æ›´æ–°ï¼ˆå¸¦è¿›åº¦æ¡ï¼‰
 * æ ¼å¼:   1/100     2.5G   100/20     1.5M      0.1200     0.1420    13.50    45.6s   50%|==========>          |
 */
static void print_progress_bar(int epoch, int total_epochs,
                               size_t batch_idx, size_t total_batches,
                               float loss, float avg_loss,
                               double speed, double eta,
                               bool is_training,
                               torch::Device device, double elapsed_time,
                               long long current_tokens, size_t current_batches) {
    // è®¡ç®—è¿›åº¦æ¡
    const int bar_width = 20;
    float progress = static_cast<float>(batch_idx + 1) / static_cast<float>(total_batches);
    int filled = static_cast<int>(progress * bar_width);
    int pct = static_cast<int>(progress * 100.0f + 0.5f);
    
    // ä½¿ç”¨ASCIIå­—ç¬¦æ„å»ºè¿›åº¦æ¡
    std::string bar;
    for (int i = 0; i < bar_width; ++i) {
        if (i < filled) {
            bar += '=';
        } else if (i == filled && filled < bar_width) {
            bar += '>';
        } else {
            bar += ' ';
        }
    }
    
    // è·å–GPUå†…å­˜ä½¿ç”¨æƒ…å†µ
    std::string gpu_mem = "N/A";
    if (device.is_cuda()) {
        try {
            c10::cuda::CUDAGuard guard(device);
            size_t allocated = 0;
            size_t total = 0;
#ifdef USE_CUDA
            size_t free = 0;
            if (cudaMemGetInfo(&free, &total) == cudaSuccess) {
                allocated = total - free;
                double allocated_gb = allocated / (1024.0 * 1024.0 * 1024.0);
                std::ostringstream gpu_oss;
                gpu_oss << std::fixed << std::setprecision(1) << allocated_gb << "G";
                gpu_mem = gpu_oss.str();
            }
#endif
        } catch (...) {
            gpu_mem = "N/A";
        }
    } else {
        gpu_mem = "0G";
    }
    
    // æ ¼å¼åŒ–æ‰¹æ¬¡æ•°é‡ï¼ˆæ˜¾ç¤ºå½“å‰æ‰¹æ¬¡/æ€»æ‰¹æ¬¡ï¼‰
    std::ostringstream batch_oss;
    batch_oss << (batch_idx + 1) << "/" << total_batches;
    
    // è®¡ç®—æ¯ç§’å¤„ç†çš„tokenæ•°é‡
    double tokens_per_sec = (elapsed_time > 0.0) ? (static_cast<double>(current_tokens) / elapsed_time) : 0.0;
    
    // æ ¼å¼åŒ–æ¯ç§’tokensæ•°é‡ï¼ˆä½¿ç”¨K/M/Gç­‰å•ä½ï¼Œæ·»åŠ /såç¼€ï¼‰
    std::string tokens_str;
    if (tokens_per_sec >= 1000000000) {
        std::ostringstream t_oss;
        t_oss << std::fixed << std::setprecision(1) << (tokens_per_sec / 1000000000.0) << "G/s";
        tokens_str = t_oss.str();
    } else if (tokens_per_sec >= 1000000) {
        std::ostringstream t_oss;
        t_oss << std::fixed << std::setprecision(1) << (tokens_per_sec / 1000000.0) << "M/s";
        tokens_str = t_oss.str();
    } else if (tokens_per_sec >= 1000) {
        std::ostringstream t_oss;
        t_oss << std::fixed << std::setprecision(1) << (tokens_per_sec / 1000.0) << "K/s";
        tokens_str = t_oss.str();
    } else {
        std::ostringstream t_oss;
        t_oss << std::fixed << std::setprecision(1) << tokens_per_sec << "/s";
        tokens_str = t_oss.str();
    }
    
    // YOLOv5é£æ ¼ï¼šè¡¨æ ¼æ ¼å¼è¾“å‡ºï¼ˆä¸epochæ±‡æ€»è¡Œæ ¼å¼ä¸€è‡´ï¼‰+ è¿›åº¦æ¡
    // æ ¼å¼: train:  1/100      2.5G        100/20      1.5M          0.1200        -         -       45.6s        |==========>          | 50%
    // YOLOv5é£æ ¼ï¼šæ‰€æœ‰åˆ—å·¦å¯¹é½
    std::ostringstream oss;
    oss << "train: "
        << std::setw(10) << std::left << (std::to_string(epoch) + "/" + std::to_string(total_epochs))
        << std::setw(12) << std::left << gpu_mem
        << std::setw(15) << std::left << batch_oss.str()
        << std::setw(15) << std::left << tokens_str
        << std::setw(15) << std::left << std::fixed << std::setprecision(4) << avg_loss;
    
    // è®­ç»ƒé˜¶æ®µï¼šval_losså’ŒBLEUæ˜¾ç¤ºä¸º"-"
    if (is_training) {
        oss << std::setw(15) << std::left << "-"
            << std::setw(10) << std::left << "-";
    } else {
        // éªŒè¯é˜¶æ®µï¼šæ˜¾ç¤ºå½“å‰æŸå¤±ï¼ˆval_lossï¼‰ï¼ŒBLEUæ˜¾ç¤ºä¸º"-"
        oss << std::setw(15) << std::left << std::fixed << std::setprecision(4) << avg_loss
            << std::setw(10) << std::left << "-";
    }
    
    oss << std::setw(10) << std::left << std::fixed << std::setprecision(1) << elapsed_time << "s"
        << std::setw(28) << std::left << ("|" + bar + "| " + std::to_string(pct) + "%");
    
    std::string progress_str = oss.str();
    
    // æ·»åŠ ç©ºæ ¼ä»¥æ¸…é™¤ä¹‹å‰å¯èƒ½æ›´é•¿çš„è¡Œå†…å®¹
    const int terminal_width = 140;
    if (progress_str.length() < terminal_width) {
        progress_str += std::string(terminal_width - progress_str.length(), ' ');
    }
    
    // ä½¿ç”¨ \r è¦†ç›–åŒä¸€è¡Œ
    std::cout << "\r" << progress_str << std::flush;
    
    // å¦‚æœæ˜¯æœ€åä¸€ä¸ª batchï¼Œæ¢è¡Œ
    if (batch_idx + 1 == total_batches) {
        std::cout << std::endl;
    }
}

// è¾…åŠ©å‡½æ•°ï¼šæ ¹æ®å½“å‰ batch ç´¢å¼•è·å–ä¸€ä¸ª Batchï¼ˆå•çº¿ç¨‹æ¨¡å¼ï¼‰
static Batch get_batch_for_index(size_t i,
                                 int batch_size,
                                 const std::vector<size_t>& indices,
                                 MTDataset& dataset,
                                 torch::Device device,
                                 const TransformerConfig& config,
                                 std::unique_ptr<CudaStreamManager>& stream_manager,
                                 double& collate_time_ms) {
    size_t start_idx = i * batch_size;
    size_t end_idx = std::min(start_idx + batch_size, indices.size());
    std::vector<size_t> batch_indices(indices.begin() + start_idx,
                                     indices.begin() + end_idx);
    
    auto collate_start = steady_clock::now();
    GPUProfiler::start_timer("collate_fn");
    
    if (device.is_cuda() && stream_manager && i > 0) {
        // åœ¨ä¼ è¾“ Stream ä¸Šå‡†å¤‡å½“å‰ batch çš„æ•°æ®
        stream_manager->set_current_stream(0);
    }
    
    Batch b = dataset.collate_fn(batch_indices, device,
                                 config.padding_idx, config.bos_idx, config.eos_idx,
                                 config.src_vocab_size, config.tgt_vocab_size);
    
    GPUProfiler::end_timer("collate_fn");
    auto collate_end = steady_clock::now();
    collate_time_ms = duration_cast<microseconds>(collate_end - collate_start).count() / 1000.0;
    return b;
}

// è¿”å› (å¹³å‡æŸå¤±, æ€»tokensæ•°, æ‰¹æ¬¡æ•°é‡)
std::tuple<float, long long, size_t> run_epoch(MTDataset& dataset,
                                               Transformer model,
                                               LossCompute& loss_compute,
                                               int batch_size,
                                               torch::Device device,
                                               const TransformerConfig& config,
                                               bool is_training,
                                               int epoch,
                                               int total_epochs) {
    // CUDA Stream ç®¡ç†å™¨ï¼šç”¨äºå¯é€‰çš„æµæ°´çº¿å¹¶è¡Œï¼ˆæ ¹æ®é…ç½®å†³å®šæ˜¯å¦å¯ç”¨ï¼‰
    std::unique_ptr<CudaStreamManager> stream_manager;
    if (device.is_cuda() && config.use_cuda_stream) {
        // âœ… é˜¶æ®µ 2ï¼šN ä¸ª Stream å®ç°æ·±åº¦æµæ°´çº¿ï¼ˆå¯é…ç½®ï¼‰
        // Stream 0: æ•°æ®ä¼ è¾“ï¼ˆBatch N+1ï¼‰
        // Stream 1: å‰å‘ä¼ æ’­ï¼ˆBatch Nï¼‰
        // Stream 2: åå‘ä¼ æ’­ï¼ˆBatch Nï¼‰
        // Stream 3+: é¢å¤–çš„æ•°æ®ä¼ è¾“æˆ–è®¡ç®—æµï¼ˆå¦‚æœ stream_count >= 4ï¼‰
        int stream_count = std::max(2, std::min(config.cuda_stream_count, 8));  // é™åˆ¶åœ¨ 2-8 ä¹‹é—´
        stream_manager = std::make_unique<CudaStreamManager>(device, stream_count);
        LOG_INFO("Using " + std::to_string(stream_count) + " CUDA Streams for deep pipeline parallelism");
    } else if (device.is_cuda() && !config.use_cuda_stream) {
        LOG_INFO("CUDA Stream disabled, using default CUDA stream");
    }

    float total_tokens = 0.0f;
    float total_loss = 0.0f;
    
    // âœ… æ–¹æ¡ˆ 1ï¼šå»¶è¿Ÿ loss æå– - ç´¯ç§¯ loss tensorï¼Œæ‰¹é‡æå–
    std::vector<torch::Tensor> loss_tensor_buffer;  // ç´¯ç§¯ loss tensor
    std::vector<float> ntokens_buffer;              // å¯¹åº”çš„ token æ•°é‡
    const size_t LOSS_EXTRACT_INTERVAL = 10;        // æ¯ 10 ä¸ª batch æå–ä¸€æ¬¡
    
    // âœ… æ–¹æ¡ˆ 2 + æ–¹æ¡ˆ 3ï¼šEvent åŒæ­¥ + å‡å°‘åŒæ­¥é¢‘ç‡ï¼ˆä¸šç•Œæ ‡å‡† + YOLOv5 ç­–ç•¥ï¼‰
    at::cuda::CUDAEvent compute_event;
    const size_t SYNC_INTERVAL = 10;  // æ¯ 10 ä¸ª batch åŒæ­¥ä¸€æ¬¡ï¼ˆä¸å»¶è¿Ÿ loss æå–ä¸€è‡´ï¼‰
    bool event_initialized = false;
    
    // âœ… é˜¶æ®µ 2ï¼š4 ä¸ª Stream æ·±åº¦æµæ°´çº¿ - Event ç®¡ç†
    at::cuda::CUDAEvent transfer_event;      // æ•°æ®ä¼ è¾“å®Œæˆäº‹ä»¶
    at::cuda::CUDAEvent forward_event;       // å‰å‘ä¼ æ’­å®Œæˆäº‹ä»¶
    at::cuda::CUDAEvent backward_event;      // åå‘ä¼ æ’­å®Œæˆäº‹ä»¶
    bool events_initialized = false;
    
    // åŸºäºå¥å­é•¿åº¦çš„ bucket é‡‡æ ·ç­–ç•¥
    // 1. å…ˆæŒ‰é•¿åº¦æ’åºå¾—åˆ°ç´¢å¼•
    LOG_DEBUG("Start bucket sampling: dataset size = " + std::to_string(dataset.size()));
    auto bucket_start_time = steady_clock::now();
    std::vector<size_t> base_indices = dataset.make_length_sorted_indices();
    auto bucket_end_time = steady_clock::now();
    double bucket_time = duration_cast<milliseconds>(bucket_end_time - bucket_start_time).count() / 1000.0;
    LOG_DEBUG("Length sorting finished: num_indices=" + std::to_string(base_indices.size()) + ", time=" + std::to_string(bucket_time) + "s");

    // 2. æŒ‰ bucket åˆ‡åˆ†ï¼Œå†åœ¨ bucket å†…éƒ¨æ‰“ä¹±
    std::vector<size_t> indices;
    indices.reserve(base_indices.size());

    const size_t bucket_size = static_cast<size_t>(batch_size) * 4;  // å¯è°ƒï¼š4 å€batch
    std::vector<size_t> bucket;
    bucket.reserve(bucket_size);

    std::random_device rd;
    std::mt19937 g(rd());

    size_t bucket_count = 0;
    size_t total_buckets = (base_indices.size() + bucket_size - 1) / bucket_size;
    LOG_DEBUG("Bucket config: bucket_size=" + std::to_string(bucket_size) + ", estimated_num_buckets=" + std::to_string(total_buckets));

    // è®°å½•åˆå§‹æ˜¾å­˜
    size_t mem_before_bucket = 0;
    if (device.is_cuda()) {
        try {
            auto stats = GPUProfiler::get_memory_stats(device);
            mem_before_bucket = stats.allocated_bytes_current;
            LOG_DEBUG("Memory before bucket sampling: " + std::to_string(mem_before_bucket / 1024 / 1024) + "MB");
        } catch (...) {
            LOG_WARN("Failed to get initial GPU memory info");
        }
    }

    for (size_t idx : base_indices) {
        bucket.push_back(idx);
        if (bucket.size() >= bucket_size) {
            // æ‰“ä¹± bucket å†…éƒ¨çš„é¡ºåº
            std::shuffle(bucket.begin(), bucket.end(), g);
            indices.insert(indices.end(), bucket.begin(), bucket.end());
            bucket_count++;
            
            // è®°å½•æ¯ä¸ª bucket å¤„ç†åçš„æ˜¾å­˜ï¼ˆæ¯10ä¸ªbucketè®°å½•ä¸€æ¬¡ï¼‰
            if (device.is_cuda() && bucket_count % 10 == 0) {
                try {
                    auto stats = GPUProfiler::get_memory_stats(device);
                    size_t mem_current = stats.allocated_bytes_current;
                    size_t mem_diff = mem_current - mem_before_bucket;
                    LOG_DEBUG("Bucket " + std::to_string(bucket_count) + "/" + std::to_string(total_buckets) + 
                             ": allocated=" + std::to_string(mem_current / 1024 / 1024) + "MB, " +
                             "increase=" + std::to_string(mem_diff / 1024 / 1024) + "MB");
                } catch (...) {
                    LOG_WARN("Exception occurred while getting bucket memory stats (ignored)");
                }
            }
            
            bucket.clear();
        }
    }
    // å¤„ç†æœ€åä¸€ä¸ªä¸æ»¡çš„ bucket
    if (!bucket.empty()) {
        std::shuffle(bucket.begin(), bucket.end(), g);
        indices.insert(indices.end(), bucket.begin(), bucket.end());
        bucket_count++;
    }
    
    LOG_DEBUG("Bucket sampling finished: num_buckets=" + std::to_string(bucket_count) + 
             ", num_indices=" + std::to_string(indices.size()));
    
    // è®°å½• bucket é‡‡æ ·åçš„æ˜¾å­˜
    if (device.is_cuda()) {
        try {
            auto stats = GPUProfiler::get_memory_stats(device);
            size_t mem_after_bucket = stats.allocated_bytes_current;
            size_t mem_diff = mem_after_bucket - mem_before_bucket;
            LOG_DEBUG("Memory after bucket sampling: " + std::to_string(mem_after_bucket / 1024 / 1024) + "MB, " +
                     "increase=" + std::to_string(mem_diff / 1024 / 1024) + "MB");
        } catch (...) {
            LOG_WARN("Failed to get memory stats after bucket sampling");
        }
    }
    
    // æŒ‰æ‰¹æ¬¡å¤„ç†æ•°æ®
    size_t num_batches = (indices.size() + batch_size - 1) / batch_size;
    LOG_DEBUG("Start batch processing: num_batches=" + std::to_string(num_batches) + ", batch_size=" + std::to_string(batch_size));
    
    // è®¡æ—¶ç›¸å…³
    auto epoch_start = steady_clock::now();
    size_t processed_samples = 0;
    
    // è®°å½•æ‰¹æ¬¡å¤„ç†å‰çš„æ˜¾å­˜
    size_t mem_before_batches = 0;
    if (device.is_cuda()) {
        try {
            auto stats = GPUProfiler::get_memory_stats(device);
            mem_before_batches = stats.allocated_bytes_current;
            LOG_DEBUG("Memory before batch processing: " + std::to_string(mem_before_batches / 1024 / 1024) + "MB");
        } catch (...) {
            LOG_WARN("Failed to get memory stats before batch processing");
        }
    }
    
    // âœ… é˜¶æ®µ 3ï¼šæ•°æ®ç¼“å­˜ï¼ˆå¦‚æœå¯ç”¨ï¼‰- ä½¿ç”¨ RAII ç®¡ç†
    std::unique_ptr<DataCache> data_cache;
    bool use_data_cache = (config.cache_size > 0 && device.is_cuda());
    DataCacheRAII data_cache_guard(nullptr);  // RAII åŒ…è£…ï¼Œç¡®ä¿ stop() è¢«è°ƒç”¨
    
    // âœ… ä½¿ç”¨å¤šè¿›ç¨‹æ•°æ®åŠ è½½å™¨ï¼ˆå¦‚æœ workers > 0ï¼‰
    std::unique_ptr<MultiProcessDataLoader> multi_loader;
    bool use_multi_loader = (config.workers > 0);
    
    if (use_data_cache) {
        // åˆ›å»ºæ•°æ®ç¼“å­˜ï¼ˆé¢„åŠ è½½å¤šä¸ª batch åˆ° GPUï¼‰
        data_cache = std::make_unique<DataCache>(config.cache_size, device);
        data_cache->start_prefetch(dataset, indices, batch_size, config);
        // ä½¿ç”¨ RAII åŒ…è£…ï¼Œç¡®ä¿åœ¨ä½œç”¨åŸŸç»“æŸæ—¶è‡ªåŠ¨è°ƒç”¨ stop()
        data_cache_guard = DataCacheRAII(data_cache.get());
        LOG_INFO("Using GPU data cache: cache_size=" + std::to_string(config.cache_size));
    } 
    if (use_multi_loader) {
        // åˆ›å»ºå¤šè¿›ç¨‹æ•°æ®åŠ è½½å™¨
        multi_loader = std::make_unique<MultiProcessDataLoader>(
            dataset, indices, batch_size, device, config,
            config.workers, config.pin_memory, config.prefetch_factor
        );
        LOG_INFO("Using multi-process data loader: workers=" + std::to_string(config.workers) +
                 ", pin_memory=" + std::string(config.pin_memory ? "true" : "false"));
    }
    
    // âœ… é˜¶æ®µ 3ï¼šæ··åˆç²¾åº¦è®­ç»ƒï¼ˆå¦‚æœå¯ç”¨ï¼‰
    std::unique_ptr<AMPScaler> amp_scaler;
    bool use_amp = (config.use_amp && device.is_cuda() && is_training);
    if (use_amp) {
        amp_scaler = std::make_unique<AMPScaler>(config.amp_init_scale, config.amp_scale_window);
        LOG_INFO("Using mixed precision training (FP16): init_scale=" + 
                 std::to_string(config.amp_init_scale) + ", scale_window=" + 
                 std::to_string(config.amp_scale_window));
    }
    
    for (size_t i = 0; i < num_batches; ++i) {
        double collate_time_ms = 0.0;
        
        // âœ… é˜¶æ®µ 3ï¼šä¼˜å…ˆä½¿ç”¨æ•°æ®ç¼“å­˜ï¼Œå…¶æ¬¡å¤šè¿›ç¨‹åŠ è½½å™¨ï¼Œæœ€åå•çº¿ç¨‹åŠ è½½
        // ä½¿ç”¨ RAII ç¡®ä¿ Batch ä¸­çš„å¼ é‡åœ¨ä½œç”¨åŸŸç»“æŸæ—¶è‡ªåŠ¨é‡Šæ”¾
        Batch batch;
        
        if (use_data_cache && data_cache) {
            auto collate_start = steady_clock::now();
            batch = data_cache->get_next();
            auto collate_end = steady_clock::now();
            collate_time_ms = duration_cast<microseconds>(collate_end - collate_start).count() / 1000.0;
            
            // æ£€æŸ¥æ˜¯å¦åŠ è½½å®Œæˆ
            if (!batch.src.defined()) {
                LOG_DEBUG("Data cache finished at batch " + std::to_string(i));
                break;
            }
        } else if (use_multi_loader && multi_loader) {
            auto collate_start = steady_clock::now();
            batch = multi_loader->next();
            auto collate_end = steady_clock::now();
            collate_time_ms = duration_cast<microseconds>(collate_end - collate_start).count() / 1000.0;
            
            // æ£€æŸ¥æ˜¯å¦åŠ è½½å®Œæˆ
            if (!batch.src.defined()) {
                LOG_DEBUG("Data loader finished at batch " + std::to_string(i));
                break;
            }
        } else {
            // å•çº¿ç¨‹æ¨¡å¼ï¼šä½¿ç”¨åŸæœ‰é€»è¾‘
            batch = get_batch_for_index(i, batch_size, indices, dataset, device,
                                        config, stream_manager, collate_time_ms);
        }
        
        // åœ¨ batch èµ‹å€¼å®Œæˆååˆ›å»º RAII guardï¼Œç¡®ä¿åœ¨å¾ªç¯ç»“æŸæ—¶è‡ªåŠ¨é‡Šæ”¾
        BatchScopeGuard batch_guard(batch);  // RAII ä¿æŠ¤ï¼Œç¡®ä¿å¼ é‡é‡Šæ”¾
        
        // âœ… é˜¶æ®µ 2ï¼š4 ä¸ª Stream æ·±åº¦æµæ°´çº¿ + Event åŒæ­¥ï¼ˆä¸šç•Œæ ‡å‡†ï¼‰
        if (device.is_cuda() && stream_manager) {
            // åˆå§‹åŒ–æ‰€æœ‰ Eventï¼ˆç¬¬ä¸€ä¸ª batchï¼‰
            if (!events_initialized) {
                transfer_event = stream_manager->create_event();
                forward_event = stream_manager->create_event();
                backward_event = stream_manager->create_event();
                compute_event = stream_manager->create_event();
                events_initialized = true;
                event_initialized = true;
            }
            
            if (i == 0) {
                // ç¬¬ä¸€ä¸ª batchï¼šç­‰å¾…æ•°æ®ä¼ è¾“å®Œæˆ
                stream_manager->synchronize(0);  // ç¬¬ä¸€ä¸ª batch éœ€è¦åŒæ­¥ä¼ è¾“
                // è®°å½•ä¼ è¾“å®Œæˆäº‹ä»¶
                stream_manager->set_current_stream(0);
                stream_manager->record_event(transfer_event, 0);
            } else {
                // åç»­ batchï¼šä½¿ç”¨ Event åŒæ­¥ Stream ä¾èµ–
                // åªåœ¨å¿…è¦æ—¶åŒæ­¥ï¼ˆæ¯ 10 ä¸ª batch æˆ–æœ€åä¸€ä¸ª batchï¼‰
                bool should_sync = ((i + 1) % SYNC_INTERVAL == 0) || (i == num_batches - 1);
                
                if (should_sync) {
                    // æ‰¹é‡åŒæ­¥ï¼šç­‰å¾…ä¸Šä¸€ä¸ª batch çš„è®¡ç®—å®Œæˆ
                    backward_event.synchronize();
                } else {
                    // éé˜»å¡æ£€æŸ¥ï¼šä¸é˜»å¡ CPU
                    if (!stream_manager->query_event(backward_event)) {
                        // äº‹ä»¶æœªå®Œæˆï¼Œä½†ä¸ç­‰å¾…ï¼Œè®© GPU ç»§ç»­å·¥ä½œ
                    }
                }
                
                // Stream 0: è®°å½•å½“å‰ batch çš„ä¼ è¾“å®Œæˆäº‹ä»¶
                // æ•°æ®ä¼ è¾“å·²åœ¨ collate_fn ä¸­å®Œæˆï¼ˆä½¿ç”¨ non_blocking=trueï¼‰
                stream_manager->set_current_stream(0);
                stream_manager->record_event(transfer_event, 0);
            }
            
            // Stream 1: å‰å‘ä¼ æ’­ï¼ˆç­‰å¾…ä¼ è¾“å®Œæˆï¼‰
            if (stream_manager->num_streams() >= 2) {
                // âœ… ä¿®å¤ï¼šä½¿ç”¨ CudaStreamManager çš„ wait_event_on_stream æ–¹æ³•
                stream_manager->wait_event_on_stream(transfer_event, 1);  // Stream 1 ç­‰å¾…ä¼ è¾“å®Œæˆ
            }
            stream_manager->set_current_stream(1);
        }
        
        // âœ… é˜¶æ®µ 3ï¼šå‰å‘ä¼ æ’­ï¼ˆæ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒï¼‰
        // éªŒè¯é˜¶æ®µä½¿ç”¨ NoGradGuard é¿å…æ„å»ºè®¡ç®—å›¾ï¼ŒèŠ‚çœæ˜¾å­˜
        torch::Tensor out;
        auto forward_start = steady_clock::now();
        if (is_training) {
            GPUProfiler::start_timer("forward");
            if (use_amp) {
                // æ··åˆç²¾åº¦è®­ç»ƒï¼šå°†è¾“å…¥è½¬æ¢ä¸º FP16
                auto src_fp16 = batch.src.to(torch::kFloat16);
                auto trg_fp16 = batch.trg.to(torch::kFloat16);
                auto src_mask_fp16 = batch.src_mask.to(torch::kFloat16);
                auto trg_mask_fp16 = batch.trg_mask.to(torch::kFloat16);
                
                // å‰å‘ä¼ æ’­ï¼ˆFP16ï¼‰
                out = model->forward(src_fp16, trg_fp16, src_mask_fp16, trg_mask_fp16);
                // è¾“å‡ºè½¬æ¢ä¸º FP32ï¼ˆç”¨äº loss è®¡ç®—ï¼‰
                out = out.to(torch::kFloat32);
            } else {
                // FP32 è®­ç»ƒ
                out = model->forward(batch.src, batch.trg, batch.src_mask, batch.trg_mask);
            }
            GPUProfiler::end_timer("forward");
        } else {
            torch::NoGradGuard no_grad;
            GPUProfiler::start_timer("forward");
            out = model->forward(batch.src, batch.trg, batch.src_mask, batch.trg_mask);
            GPUProfiler::end_timer("forward");
        }
        auto forward_end = steady_clock::now();
        double forward_time_ms = duration_cast<microseconds>(forward_end - forward_start).count() / 1000.0;
        
        // âœ… é˜¶æ®µ 2ï¼šè®°å½•å‰å‘ä¼ æ’­å®Œæˆäº‹ä»¶
        if (device.is_cuda() && stream_manager && events_initialized) {
            stream_manager->record_event(forward_event, 1);  // åœ¨ Stream 1 ä¸Šè®°å½•å‰å‘å®Œæˆäº‹ä»¶
        }
        
        // âœ… é˜¶æ®µ 2ï¼šStream 2 ç­‰å¾…å‰å‘ä¼ æ’­å®Œæˆ
        if (device.is_cuda() && stream_manager && stream_manager->num_streams() >= 3) {
            // âœ… ä¿®å¤ï¼šä½¿ç”¨ CudaStreamManager çš„ wait_event_on_stream æ–¹æ³•
            stream_manager->wait_event_on_stream(forward_event, 2);  // Stream 2 ç­‰å¾…å‰å‘å®Œæˆ
            stream_manager->set_current_stream(2);  // åˆ‡æ¢åˆ° Stream 2 è¿›è¡Œåå‘ä¼ æ’­
        }
        
        // âœ… é˜¶æ®µ 3ï¼šè®¡ç®—æŸå¤±ï¼ˆæ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒï¼‰
        auto loss_start = steady_clock::now();
        GPUProfiler::start_timer("loss_compute");
        
        torch::Tensor loss_tensor;
        bool has_backward = false;
        
        if (use_amp && amp_scaler && is_training) {
            // æ··åˆç²¾åº¦è®­ç»ƒï¼šåˆ†ç¦»åå‘ä¼ æ’­å’Œä¼˜åŒ–å™¨æ›´æ–°
            // 1. è®¡ç®— lossï¼ˆä¸æ‰§è¡Œåå‘ä¼ æ’­ï¼‰
            loss_tensor = loss_compute.compute_loss_and_backward(
                out, batch.trg_y, static_cast<float>(batch.ntokens));
            
            // 2. ç¼©æ”¾ lossï¼ˆåœ¨åå‘ä¼ æ’­ä¹‹å‰ï¼‰
            loss_tensor = amp_scaler->scale(loss_tensor);
            
            // 3. æ‰§è¡Œåå‘ä¼ æ’­ï¼ˆloss å·²ç¼©æ”¾ï¼‰
            loss_tensor.backward();
            
            // 4. å–æ¶ˆç¼©æ”¾æ¢¯åº¦
            auto base_optimizer = loss_compute.get_base_optimizer();
            if (base_optimizer) {
                amp_scaler->unscale(base_optimizer);
            }
            
            // 5. å¦‚æœæ¢¯åº¦æº¢å‡ºï¼Œè·³è¿‡ä¼˜åŒ–å™¨æ›´æ–°
            if (!amp_scaler->has_overflow()) {
                loss_compute.optimizer_step();
                has_backward = true;
            } else {
                // æ¢¯åº¦æº¢å‡ºï¼Œè·³è¿‡æ›´æ–°
                LOG_WARN("Gradient overflow detected, skipping optimizer step");
            }
            
            // 6. æ›´æ–°ç¼©æ”¾å› å­
            amp_scaler->update();
        } else {
            // æ ‡å‡†è®­ç»ƒï¼šä½¿ç”¨åŸæœ‰æ–¹æ³•
            std::tie(loss_tensor, has_backward) = loss_compute.compute_loss_tensor(
                out, batch.trg_y, static_cast<float>(batch.ntokens));
        }
        
        GPUProfiler::end_timer("loss_compute");
        auto loss_end = steady_clock::now();
        double loss_time_ms = duration_cast<microseconds>(loss_end - loss_start).count() / 1000.0;
        
        // âœ… é˜¶æ®µ 2ï¼šè®°å½•åå‘ä¼ æ’­å®Œæˆäº‹ä»¶ï¼ˆåœ¨ Stream 2 ä¸Šï¼‰
        if (device.is_cuda() && stream_manager && events_initialized) {
            if (stream_manager->num_streams() >= 3) {
                stream_manager->record_event(backward_event, 2);  // åœ¨ Stream 2 ä¸Šè®°å½•åå‘å®Œæˆäº‹ä»¶
            } else {
                // å¦‚æœåªæœ‰ 2 ä¸ª Streamï¼Œåœ¨ Stream 1 ä¸Šè®°å½•
                stream_manager->record_event(backward_event, 1);
            }
            // åŒæ—¶è®°å½• compute_eventï¼ˆç”¨äºå…¼å®¹åŸæœ‰é€»è¾‘ï¼‰
            stream_manager->record_event(compute_event, (stream_manager->num_streams() >= 3) ? 2 : 1);
        }
        
        // âœ… å»¶è¿Ÿæå–ï¼šç´¯ç§¯ loss tensorï¼Œæ‰¹é‡æå–
        loss_tensor_buffer.push_back(loss_tensor);
        ntokens_buffer.push_back(static_cast<float>(batch.ntokens));
        
        // ç´¯åŠ  token æ•°é‡ï¼ˆç«‹å³ç´¯åŠ ï¼Œç”¨äºç»Ÿè®¡ï¼‰
        total_tokens += batch.ntokens;
        
        // æ¯ N ä¸ª batch æˆ–æœ€åä¸€ä¸ª batch æ—¶ï¼Œæ‰¹é‡æå– loss å€¼
        bool should_extract = ((i + 1) % LOSS_EXTRACT_INTERVAL == 0) || (i == num_batches - 1);
        
        float current_loss = 0.0f;  // å½“å‰ batch çš„ lossï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        if (should_extract && !loss_tensor_buffer.empty()) {
            // æ‰¹é‡æå–æ‰€æœ‰ç´¯ç§¯çš„ loss å€¼ï¼ˆå‡å°‘åŒæ­¥æ¬¡æ•°ï¼‰
            for (size_t j = 0; j < loss_tensor_buffer.size(); ++j) {
                float loss_value = loss_tensor_buffer[j].item<float>();  // æ‰¹é‡åŒæ­¥
                total_loss += loss_value * ntokens_buffer[j];
                
                // æœ€åä¸€ä¸ª loss ç”¨äºå½“å‰æ˜¾ç¤º
                if (j == loss_tensor_buffer.size() - 1) {
                    current_loss = loss_value;
                }
                
                // é‡Šæ”¾ loss tensor
                loss_tensor_buffer[j] = torch::Tensor();
            }
            loss_tensor_buffer.clear();
            ntokens_buffer.clear();
        } else {
            // å¦‚æœä¸éœ€è¦æå–ï¼Œä½¿ç”¨ä¼°ç®—å€¼ï¼ˆåŸºäºå†å²å¹³å‡å€¼ï¼‰
            // æ³¨æ„ï¼šè¿™åªæ˜¯ç”¨äºæ˜¾ç¤ºï¼Œå®é™…ç´¯åŠ ä¼šåœ¨æ‰¹é‡æå–æ—¶è¿›è¡Œ
            float avg_loss_so_far = (total_tokens > 0.0f) ? (total_loss / total_tokens) : 0.0f;
            current_loss = avg_loss_so_far;  // ä½¿ç”¨å¹³å‡å€¼ä½œä¸ºä¸´æ—¶æ˜¾ç¤ºå€¼
        }
        
        size_t current_batch_size = static_cast<size_t>(batch.src.size(0));
        processed_samples += current_batch_size;
        
        // âœ… ç«‹å³é‡Šæ”¾æ‰€æœ‰å¼ é‡ï¼ˆå…³é”®ä¿®å¤ï¼šé˜²æ­¢æ˜¾å­˜æ³„æ¼ï¼‰
        // ä½¿ç”¨ RAIIï¼šbatch_guard ä¼šåœ¨ä½œç”¨åŸŸç»“æŸæ—¶è‡ªåŠ¨é‡Šæ”¾ Batch ä¸­çš„å¼ é‡
        // ä½†ä¸ºäº†åŠæ—¶é‡Šæ”¾ï¼Œæˆ‘ä»¬æ˜¾å¼é‡Šæ”¾ out å¼ é‡
        out = torch::Tensor();
        // Batch ä¸­çš„å¼ é‡ç”± batch_guard åœ¨ä½œç”¨åŸŸç»“æŸæ—¶è‡ªåŠ¨é‡Šæ”¾
        // å¦‚æœéœ€è¦ç«‹å³é‡Šæ”¾ï¼Œå¯ä»¥è°ƒç”¨ batch_guard.release()
        
        // æ³¨æ„ï¼šdata_cache_guard ä¼šåœ¨å‡½æ•°è¿”å›æ—¶è‡ªåŠ¨è°ƒç”¨ stop()ï¼Œæ— éœ€æ‰‹åŠ¨è°ƒç”¨
    
    // âœ… ä¼˜åŒ–ï¼šå‡å°‘æ˜¾å­˜ç»Ÿè®¡é¢‘ç‡ï¼Œé¿å…é¢‘ç¹åŒæ­¥
    // æ¯ 50 ä¸ª batch æˆ–æ¯ä¸ª bucket ç»“æŸæ—¶è®°å½•ï¼ˆå‡å°‘åŒæ­¥æ“ä½œï¼‰
    if (device.is_cuda() && ((i + 1) % 50 == 0 || (i + 1) % bucket_size == 0)) {
            try {
                auto stats = GPUProfiler::get_memory_stats(device);
                size_t mem_current = stats.allocated_bytes_current;
                size_t mem_reserved = stats.reserved_bytes_current;
                size_t mem_diff = mem_current - mem_before_batches;
                
                // åˆ¤æ–­æ˜¯å¦åœ¨ bucket è¾¹ç•Œ
                bool is_bucket_end = ((i + 1) % bucket_size == 0);
                std::string log_prefix = is_bucket_end ? "[Bucket end] " : "";
                
                LOG_DEBUG(log_prefix + "Batch " + std::to_string(i + 1) + "/" + std::to_string(num_batches) +
                         ": allocated=" + std::to_string(mem_current / 1024 / 1024) + "MB, " +
                         "reserved=" + std::to_string(mem_reserved / 1024 / 1024) + "MB, " +
                         "increase=" + std::to_string(mem_diff / 1024 / 1024) + "MB");
                
                // å¦‚æœæ˜¯ bucket ç»“æŸï¼Œå¼ºåˆ¶æ¸…ç† CUDA ç¼“å­˜
                if (is_bucket_end) {
                    // Python: torch.cuda.empty_cache()
                    // C++: ä½¿ç”¨ c10::cuda::CUDACachingAllocator::emptyCache() æ¸…ç†ç¼“å­˜
                    c10::cuda::CUDACachingAllocator::emptyCache();
                    auto stats_after = GPUProfiler::get_memory_stats(device);
                    size_t mem_after_cache = stats_after.allocated_bytes_current;
                    LOG_DEBUG("[Bucket end] Memory after empty cache: " + std::to_string(mem_after_cache / 1024 / 1024) + "MB, " +
                             "released=" + std::to_string((mem_current - mem_after_cache) / 1024 / 1024) + "MB");
                }
            } catch (...) {
                LOG_WARN("Exception occurred while getting batch memory stats or emptying cache (ignored)");
            }
        }
        
    // è®¡ç®—é€Ÿåº¦å’Œå‰©ä½™æ—¶é—´ï¼ˆä½¿ç”¨ä» epoch å¼€å§‹çš„æ€»æ—¶é—´ï¼‰
        auto batch_end = steady_clock::now();
        double elapsed_time = duration_cast<milliseconds>(batch_end - epoch_start).count() / 1000.0;
        double speed = (elapsed_time > 0.0) ? (processed_samples / elapsed_time) : 0.0;
        
        // è®¡ç®—å¹³å‡æŸå¤±
        float avg_loss_so_far = (total_tokens > 0.0f)
            ? (total_loss / total_tokens)
            : 0.0f;
        
        // è®¡ç®—å‰©ä½™æ—¶é—´ï¼ˆETAï¼‰ï¼šä½¿ç”¨å‰©ä½™batchæ•°è®¡ç®—æ›´å‡†ç¡®
        double eta = 0.0;
        if (speed > 0.0 && i + 1 < num_batches) {
            size_t remaining_batches = num_batches - i - 1;
            // ä½¿ç”¨å¹³å‡æ¯ä¸ªbatchçš„æ ·æœ¬æ•°æ¥ä¼°ç®—å‰©ä½™æ ·æœ¬æ•°
            double avg_samples_per_batch = static_cast<double>(processed_samples) / (i + 1);
            double remaining_samples = remaining_batches * avg_samples_per_batch;
            eta = remaining_samples / speed;
        }
        
        // âœ… ä¼˜åŒ–ï¼šå‡å°‘è¿›åº¦æ¡æ›´æ–°é¢‘ç‡ï¼Œé¿å…é¢‘ç¹è¾“å‡ºå½±å“æ€§èƒ½
        // æ¯ 10 ä¸ª batch æˆ–æœ€åä¸€ä¸ª batch æ›´æ–°ä¸€æ¬¡
        if (i % 10 == 0 || i == num_batches - 1) {
            print_progress_bar(epoch, total_epochs, i, num_batches,
                              current_loss, avg_loss_so_far, speed, eta, is_training, device, elapsed_time,
                              static_cast<long long>(total_tokens), num_batches);
        }
        
        // å®šæœŸæ¸…ç†CUDAç¼“å­˜ï¼ˆæ¯50ä¸ªbatchæ¸…ç†ä¸€æ¬¡ï¼Œé¿å…é¢‘ç¹æ¸…ç†å½±å“æ€§èƒ½ï¼‰
        if (device.is_cuda() && (i + 1) % 50 == 0) {
           // torch::cuda::empty_cache();  // âœ… å¯ç”¨ï¼šå¼ºåˆ¶é‡Šæ”¾ CUDA ç¼“å­˜
        }
    }
    
    // âœ… ç¡®ä¿æ‰€æœ‰ç´¯ç§¯çš„ loss tensor éƒ½å·²æå–ï¼ˆé˜²æ­¢é—æ¼ï¼‰
    if (!loss_tensor_buffer.empty()) {
        // âœ… é˜¶æ®µ 2ï¼šç¡®ä¿æœ€åä¸€ä¸ª batch çš„æ‰€æœ‰æ“ä½œå®Œæˆï¼ˆæ‰¹é‡åŒæ­¥ï¼‰
        if (device.is_cuda() && stream_manager && events_initialized) {
            // åŒæ­¥æ‰€æœ‰ Stream ä¸Šçš„æ“ä½œ
            backward_event.synchronize();  // ç¡®ä¿åå‘ä¼ æ’­å®Œæˆ
            compute_event.synchronize();   // ç¡®ä¿æ‰€æœ‰è®¡ç®—å®Œæˆ
        }
        
        for (size_t j = 0; j < loss_tensor_buffer.size(); ++j) {
            float loss_value = loss_tensor_buffer[j].item<float>();
            total_loss += loss_value * ntokens_buffer[j];
            loss_tensor_buffer[j] = torch::Tensor();
        }
        loss_tensor_buffer.clear();
        ntokens_buffer.clear();
    }
    
    
    // âœ… æ€§èƒ½ç“¶é¢ˆè¯Šæ–­ï¼šåœ¨ç¬¬ä¸€ä¸ªepochç»“æŸåæ‰“å°è¯¦ç»†åˆ†æ
    if (epoch == 1 && is_training) {
        GPUProfiler::print_summary();
        GPUProfiler::check_gpu_utilization(device);
        
        // è®¡ç®—å¹³å‡æ—¶é—´ï¼ˆä» GPUProfiler è·å–ï¼‰
        auto collate_info = GPUProfiler::get_timing_info("collate_fn");
        auto forward_info = GPUProfiler::get_timing_info("forward");
        auto loss_info = GPUProfiler::get_timing_info("loss_compute");
        
        double avg_collate = (collate_info.count > 0) ? (collate_info.total_time_ms / collate_info.count) : 0.0;
        double avg_forward = (forward_info.count > 0) ? (forward_info.total_time_ms / forward_info.count) : 0.0;
        double avg_loss = (loss_info.count > 0) ? (loss_info.total_time_ms / loss_info.count) : 0.0;
        int collate_count = collate_info.count;
        int forward_count = forward_info.count;
        int loss_count = loss_info.count;
        
        // ä¼°ç®—æ€» batch æ—¶é—´ï¼ˆå‡è®¾å…¶ä»–æ—¶é—´ä¸º 10%ï¼‰
        double estimated_total = (avg_collate + avg_forward + avg_loss) / 0.9;
        double collate_ratio = (estimated_total > 0) ? (avg_collate / estimated_total * 100.0) : 0.0;
        double compute_ratio = (estimated_total > 0) ? ((avg_forward + avg_loss) / estimated_total * 100.0) : 0.0;
        double other_ratio = 100.0 - collate_ratio - compute_ratio;
        
        // âœ… è¯¦ç»†æ€§èƒ½ç“¶é¢ˆè¯Šæ–­
        LOG_INFO("========== Performance Bottleneck Diagnosis ==========");
        LOG_INFO("Time Distribution (from GPUProfiler):");
        LOG_INFO("  Data loading (collate_fn): " + std::to_string(collate_ratio) + "% (" + 
                 std::to_string(avg_collate) + " ms, " + std::to_string(collate_count) + " calls)");
        LOG_INFO("  GPU computation (forward+loss): " + std::to_string(compute_ratio) + "% (" + 
                 std::to_string(avg_forward + avg_loss) + " ms)");
        LOG_INFO("  Other (sync/wait/overhead): " + std::to_string(other_ratio) + "%");
        LOG_INFO("");
        
        // è¯†åˆ«ç“¶é¢ˆå¹¶ç»™å‡ºå»ºè®®
        bool has_bottleneck = false;
        
        if (collate_ratio > 50.0) {
            has_bottleneck = true;
            LOG_WARN("ğŸ”´ BOTTLENECK: Data loading is the bottleneck!");
            LOG_INFO("  Current configuration:");
            LOG_INFO("    --workers: " + std::to_string(config.workers) + 
                     (config.workers == 0 ? " (single-threaded)" : " (multi-threaded)"));
            LOG_INFO("    --pin-memory: " + std::string(config.pin_memory ? "true" : "false"));
            LOG_INFO("    --prefetch-factor: " + std::to_string(config.prefetch_factor));
            LOG_INFO("    --cache-size: " + std::to_string(config.cache_size));
            LOG_INFO("  Recommendations:");
            if (config.workers == 0) {
                LOG_INFO("    1. â­ Enable multi-process loading: --workers 8");
            }
            if (config.cache_size == 0) {
                LOG_INFO("    2. â­ Enable GPU data cache: --cache-size 2");
            }
            if (!config.pin_memory) {
                LOG_INFO("    3. â­ Enable pin_memory: --pin-memory true");
            }
            if (config.prefetch_factor < 2) {
                LOG_INFO("    4. â­ Increase prefetch: --prefetch-factor 4");
            }
            LOG_INFO("");
        }
        
        if (compute_ratio < 30.0) {
            has_bottleneck = true;
            LOG_WARN("ğŸ”´ BOTTLENECK: GPU computation time is too low!");
            LOG_INFO("  Current configuration:");
            LOG_INFO("    --batch-size: " + std::to_string(config.batch_size));
            LOG_INFO("    --d-model: " + std::to_string(config.d_model));
            LOG_INFO("    --n-layers: " + std::to_string(config.n_layers));
            LOG_INFO("    --use-cuda-stream: " + std::string(config.use_cuda_stream ? "true" : "false"));
            LOG_INFO("  Recommendations:");
            if (config.batch_size < 64) {
                LOG_INFO("    1. â­ Increase batch size: --batch-size 64 (or 128)");
            }
            if (!config.use_cuda_stream) {
                LOG_INFO("    2. â­ Enable CUDA Stream: --use-cuda-stream true");
            }
            if (config.d_model < 512 || config.n_layers < 6) {
                LOG_INFO("    3. Consider increasing model size: --d-model 512 --n-layers 6");
            }
            LOG_INFO("");
        }
        
        if (other_ratio > 20.0) {
            has_bottleneck = true;
            LOG_WARN("ğŸŸ  WARNING: High synchronization/wait time!");
            LOG_INFO("  Recommendations:");
            LOG_INFO("    1. â­ Enable CUDA Stream: --use-cuda-stream true");
            LOG_INFO("    2. Loss extraction is already optimized (every 10 batches)");
            LOG_INFO("    3. Memory stats frequency is already optimized (every 50 batches)");
            LOG_INFO("");
        }
        
        // GPU åˆ©ç”¨ç‡ä¼°ç®—
        double estimated_gpu_util = compute_ratio;
        if (estimated_gpu_util < 30.0) {
            LOG_WARN("ğŸ”´ GPU utilization is very low: " + std::to_string(estimated_gpu_util) + "%");
        } else if (estimated_gpu_util < 60.0) {
            LOG_WARN("ğŸŸ  GPU utilization is moderate: " + std::to_string(estimated_gpu_util) + "%");
        } else {
            LOG_INFO("âœ… GPU utilization is good: " + std::to_string(estimated_gpu_util) + "%");
        }
        
        if (!has_bottleneck) {
            LOG_INFO("âœ… No major bottlenecks detected. Performance looks good!");
        }
        
        LOG_INFO("=====================================================");
        LOG_INFO("For detailed analysis, see: PERFORMANCE_BOTTLENECK_ANALYSIS.md");
        LOG_INFO("=====================================================");
    }
    
    // epochç»“æŸåæ¸…ç†CUDAç¼“å­˜ï¼ˆä½¿ç”¨ CUDACachingAllocator::emptyCache æ›¿ä»£ torch::cuda::empty_cacheï¼‰
    if (device.is_cuda()) {
        try {
            auto stats_before = GPUProfiler::get_memory_stats(device);
            size_t mem_before = stats_before.allocated_bytes_current;
            
            // Python: torch.cuda.empty_cache()
            // C++: ä½¿ç”¨ c10::cuda::CUDACachingAllocator::emptyCache() æ¸…ç†ç¼“å­˜
            c10::cuda::CUDACachingAllocator::emptyCache();
            torch::cuda::synchronize();  // ç¡®ä¿æ‰€æœ‰ CUDA å†…å­˜é‡Šæ”¾ååŒæ­¥

            auto stats_after = GPUProfiler::get_memory_stats(device);
            size_t mem_after = stats_after.allocated_bytes_current;
            
            LOG_DEBUG("Clear cache at epoch end: before=" + std::to_string(mem_before / 1024 / 1024) + "MB, " +
                     "after=" + std::to_string(mem_after / 1024 / 1024) + "MB, " +
                     "released=" + std::to_string((mem_before - mem_after) / 1024.0 / 1024.0) + "MB");
        } catch (...) {
            LOG_WARN("Failed to get memory stats at epoch end");
            c10::cuda::CUDACachingAllocator::emptyCache();
            torch::cuda::synchronize();
        }
    }
    
    float avg_loss = (total_tokens > 0.0f) ? (total_loss / total_tokens) : 0.0f;
    long long total_tokens_long = static_cast<long long>(total_tokens);
    /*{
        std::ostringstream oss;
        oss << (is_training ? "[Train] " : "[Eval] ")
            << "Epochç»“æŸ, å¹³å‡æŸå¤±=" << std::fixed << std::setprecision(4) << avg_loss
            << ", æ€»tokenæ•°=" << total_tokens_long
            << ", æ‰¹æ¬¡æ•°=" << num_batches;
        LOG_INFO(oss.str());
    }*/
    return std::make_tuple(avg_loss, total_tokens_long, num_batches);
}

void train(MTDataset& train_dataset,
           MTDataset& dev_dataset,
           Transformer model,
           torch::nn::CrossEntropyLoss criterion,
           std::shared_ptr<NoamOpt> optimizer,
           const TransformerConfig& config,
           torch::Device device) {
    
    // åˆ›å»ºå®éªŒæ–‡ä»¶å¤¹ï¼ˆå¯¹é½ Python ç‰ˆ create_exp_folderï¼Œæ”¯æŒ YOLOv5 é£æ ¼ï¼‰
    auto [exp_folder, weights_folder] = create_exp_folder_cpp(
        config.project, config.name, config.exist_ok);
    LOG_INFO("Project dir: " + config.project);
    LOG_INFO("Experiment name: " + config.name);
    LOG_INFO("Experiment dir: " + exp_folder);
    LOG_INFO("Weights dir: " + weights_folder);
    
    // è®¾ç½®æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤å†™å…¥åˆ°å®éªŒç›®å½•ï¼‰
    std::string log_file_path = exp_folder + "/training.log";
    Logger::set_log_file(log_file_path);
    LOG_INFO("Log file: " + log_file_path);
    
    // ä¿å­˜è®­ç»ƒé…ç½®æ–‡ä»¶ï¼ˆYOLOv5 é£æ ¼ï¼‰
    save_config_file(config, exp_folder);
    
    // YOLOv5 é£æ ¼ï¼šåŸºäºéªŒè¯æŸå¤±ä¿å­˜æœ€ä½³æ¨¡å‹
    float best_val_loss = std::numeric_limits<float>::infinity();  // æœ€å°éªŒè¯æŸå¤±
    std::string best_path = weights_folder + "/best.pth";
    std::string last_path = weights_folder + "/last.pth";
    
    // åˆ›å»ºæŸå¤±è®¡ç®—å™¨
    auto loss_compute_train = LossCompute(model->get_generator(), criterion, optimizer);
    auto loss_compute_eval = LossCompute(model->get_generator(), criterion, nullptr);
    LOG_INFO("LossCompute objects created (train & eval)");
    
    // è®¡ç®—è®­ç»ƒæ•°æ®é›†çš„bucketé‡‡æ ·ä¿¡æ¯ï¼ˆåœ¨è®­ç»ƒå¼€å§‹å‰æ‰“å°ï¼‰
    const size_t bucket_size = static_cast<size_t>(config.batch_size) * 4;  // å¯è°ƒï¼š4 å€batch
    size_t train_dataset_size = train_dataset.size();
    size_t train_num_batches = (train_dataset_size + config.batch_size - 1) / config.batch_size;
    LOG_INFO("Using length-based bucket sampling: bucket_size=" + std::to_string(bucket_size) +
             ", num_samples=" + std::to_string(train_dataset_size) + ", num_batches=" + std::to_string(train_num_batches));
    
    // YOLOv5é£æ ¼ï¼šåœ¨è®­ç»ƒå¼€å§‹å‰æ‰“å°è¡¨å¤´
    std::cout << std::endl;
    // è¡¨å¤´æ ¼å¼ï¼štrain: Epoch   GPU_mem   Batch      Tokens     train_loss    val_loss     BLEU     time   è¿›åº¦æ¡
    // æ³¨æ„ï¼šå®½åº¦è¦ä¸å®é™…è¾“å‡ºå®Œå…¨ä¸€è‡´ï¼Œè¿›åº¦æ¡éƒ¨åˆ†å›ºå®šä¸º28ä¸ªå­—ç¬¦ï¼ˆ"|====================| 100%"ï¼‰
    // YOLOv5é£æ ¼ï¼šè¡¨å¤´å­—æ®µå·¦å¯¹é½
    std::cout << "train: "
              << std::setw(10) << std::left << "Epoch"
              << std::setw(12) << std::left << "GPU_mem"
              << std::setw(15) << std::left << "Batch"
              << std::setw(15) << std::left << "Tokens"
              << std::setw(15) << std::left << "train_loss"
              << std::setw(15) << std::left << "val_loss"
              << std::setw(10) << std::left << "BLEU"
              << std::setw(10) << std::left << "time"
              << std::setw(28) << std::left << "è¿›åº¦æ¡"
              << std::endl;
    
    // è®­ç»ƒå¾ªç¯
    for (int epoch = 1; epoch <= config.epoch_num; ++epoch) {
        // è®°å½•epochå¼€å§‹æ—¶é—´
        auto epoch_start_time = std::chrono::steady_clock::now();
        
        // è®­ç»ƒé˜¶æ®µ
        model->train();
        auto [train_loss, train_tokens, train_batches] = run_epoch(train_dataset, model, loss_compute_train,
                                                                  config.batch_size, device, config, true,
                                                                  epoch, config.epoch_num);
        
        // éªŒè¯é˜¶æ®µ
        model->eval();
        auto [dev_loss, dev_tokens, dev_batches] = run_epoch(dev_dataset, model, loss_compute_eval,
                                                              config.batch_size, device, config, false,
                                                              epoch, config.epoch_num);
        
        // è®¡ç®—BLEUåˆ†æ•°ï¼ˆç”¨äºç›‘æ§ï¼Œä½†ä¸ç”¨äºä¿å­˜æ¨¡å‹ï¼‰
        float bleu_score = evaluate(dev_dataset, model, config, device);
        
        // è®¡ç®—epochæ€»æ—¶é—´
        auto epoch_end_time = std::chrono::steady_clock::now();
        auto epoch_duration = std::chrono::duration_cast<std::chrono::milliseconds>(
            epoch_end_time - epoch_start_time).count() / 1000.0;
        
        // è·å–GPUå†…å­˜
        std::string gpu_mem = "N/A";
        if (device.is_cuda()) {
            try {
                c10::cuda::CUDAGuard guard(device);
                size_t allocated = 0;
                size_t total = 0;
#ifdef USE_CUDA
                size_t free = 0;
                if (cudaMemGetInfo(&free, &total) == cudaSuccess) {
                    allocated = total - free;
                    double allocated_gb = allocated / (1024.0 * 1024.0 * 1024.0);
                    std::ostringstream gpu_oss;
                    gpu_oss << std::fixed << std::setprecision(1) << allocated_gb << "G";
                    gpu_mem = gpu_oss.str();
                }
#endif
            } catch (...) {
                gpu_mem = "N/A";
            }
        } else {
            gpu_mem = "0G";
        }
        
        // YOLOv5é£æ ¼ï¼šè¡¨æ ¼æ ¼å¼è¾“å‡ºepochç»“æœ
        // æ ¼å¼å¯¹é½è¡¨å¤´ï¼šEpoch   GPU_mem   Batch   Tokens   train_loss   val_loss   BLEU     time
        // ç¤ºä¾‹ï¼š       1/100     2.5G   100/20     1.5M      0.1234     0.1456    12.34    45.6s
        
        // æ ¼å¼åŒ–æ‰¹æ¬¡æ•°é‡ï¼ˆæ˜¾ç¤ºè®­ç»ƒå’ŒéªŒè¯çš„æ‰¹æ¬¡ï¼Œæ ¼å¼ï¼štrain_batches/val_batchesï¼‰
        std::ostringstream batch_oss;
        batch_oss << train_batches << "/" << dev_batches;
        
        // è®¡ç®—æ¯ç§’å¤„ç†çš„tokenæ•°é‡
        double tokens_per_sec = (epoch_duration > 0.0) ? (static_cast<double>(train_tokens) / epoch_duration) : 0.0;
        
        // æ ¼å¼åŒ–æ¯ç§’tokensæ•°é‡ï¼ˆä½¿ç”¨K/M/Gç­‰å•ä½ï¼Œæ·»åŠ /såç¼€ï¼‰
        std::string tokens_str;
        if (tokens_per_sec >= 1000000000) {
            std::ostringstream t_oss;
            t_oss << std::fixed << std::setprecision(1) << (tokens_per_sec / 1000000000.0) << "G/s";
            tokens_str = t_oss.str();
        } else if (tokens_per_sec >= 1000000) {
            std::ostringstream t_oss;
            t_oss << std::fixed << std::setprecision(1) << (tokens_per_sec / 1000000.0) << "M/s";
            tokens_str = t_oss.str();
        } else if (tokens_per_sec >= 1000) {
            std::ostringstream t_oss;
            t_oss << std::fixed << std::setprecision(1) << (tokens_per_sec / 1000.0) << "K/s";
            tokens_str = t_oss.str();
        } else {
            std::ostringstream t_oss;
            t_oss << std::fixed << std::setprecision(1) << tokens_per_sec << "/s";
            tokens_str = t_oss.str();
        }
        
        // YOLOv5é£æ ¼ï¼šæŒ‰ç…§ç¤ºä¾‹æ ¼å¼è¾“å‡ºï¼šval: å‰ç¼€ï¼Œæ‰€æœ‰åˆ—å·¦å¯¹é½ï¼Œæœ€åæ·»åŠ è¿›åº¦æ¡ï¼ˆ|====================| 100%ï¼‰
        // æ ¼å¼è¦ä¸è¡¨å¤´å®Œå…¨å¯¹é½
        std::string full_bar(20, '=');  // 100%è¿›åº¦æ¡
        std::cout << "val: "
                  << std::setw(10) << std::left << (std::to_string(epoch) + "/" + std::to_string(config.epoch_num))
                  << std::setw(12) << std::left << gpu_mem
                  << std::setw(15) << std::left << batch_oss.str()
                  << std::setw(15) << std::left << tokens_str
                  << std::setw(15) << std::left << std::fixed << std::setprecision(4) << train_loss
                  << std::setw(15) << std::left << std::fixed << std::setprecision(4) << dev_loss
                  << std::setw(10) << std::left << std::fixed << std::setprecision(2) << bleu_score
                  << std::setw(10) << std::left << std::fixed << std::setprecision(1) << epoch_duration << "s"
                  << std::setw(28) << std::left << ("|" + full_bar + "| 100%")
                  << std::endl;
        
        // YOLOv5 é£æ ¼ï¼šåŸºäºéªŒè¯æŸå¤±ä¿å­˜æœ€ä½³æ¨¡å‹
        // å¦‚æœå½“å‰éªŒè¯æŸå¤±å°äºå†å²æœ€å°æŸå¤±ï¼Œä¿å­˜ä¸º best.pth
        if (dev_loss < best_val_loss) {
            try {
                // ä¿å­˜å‰æ¸…ç†CUDAç¼“å­˜ï¼Œé‡Šæ”¾æœªä½¿ç”¨çš„æ˜¾å­˜
                if (device.is_cuda()) {
                 //   torch::cuda::empty_cache();
                }
                // ç›´æ¥ä¿å­˜æ¨¡å‹ï¼ˆä¸åŒ…å«é…ç½®å‚æ•°ï¼‰
                torch::save(model, best_path);
                {
                    std::ostringstream oss;
                    if (best_val_loss == std::numeric_limits<float>::infinity()) {
                        oss << "ä¿å­˜æœ€ä½³æ¨¡å‹: " << best_path 
                            << " (ValLoss=" << std::fixed << std::setprecision(3) << dev_loss << ")";
                    } else {
                        oss << "ä¿å­˜æœ€ä½³æ¨¡å‹: " << best_path 
                            << " (ValLoss=" << std::fixed << std::setprecision(3) << dev_loss
                            << " < " << std::fixed << std::setprecision(3) << best_val_loss << ")";
                    }
                    LOG_INFO(oss.str());
                }
                best_val_loss = dev_loss;
                // ä¿å­˜åæ¸…ç†CUDAç¼“å­˜
                if (device.is_cuda()) {
                  //  torch::cuda::empty_cache();
                }
            } catch (const std::exception& e) {
                LOG_ERROR(std::string("ä¿å­˜æœ€ä½³æ¨¡å‹å¤±è´¥: ") + best_path + ", é”™è¯¯: " + e.what());
            }
        }
        
        // YOLOv5 é£æ ¼ï¼šæ¯ä¸ª epoch éƒ½ä¿å­˜ last.pthï¼ˆè¦†ç›–ä¹‹å‰çš„ï¼‰
        try {
            // ä¿å­˜å‰æ¸…ç†CUDAç¼“å­˜
            if (device.is_cuda()) {
             //   torch::cuda::empty_cache();
            }
            // ç›´æ¥ä¿å­˜æ¨¡å‹ï¼ˆä¸åŒ…å«é…ç½®å‚æ•°ï¼‰
            torch::save(model, last_path);
            {
                std::ostringstream oss;
                oss << "ä¿å­˜æœ€åæ¨¡å‹: " << last_path 
                    << " (Epoch " << epoch << ", ValLoss=" 
                    << std::fixed << std::setprecision(3) << dev_loss << ")";
                LOG_INFO(oss.str());
            }
            // ä¿å­˜åæ¸…ç†CUDAç¼“å­˜
            if (device.is_cuda()) {
            //   torch::cuda::empty_cache();
            }
        } catch (const std::exception& e) {
            LOG_ERROR(std::string("ä¿å­˜æœ€åæ¨¡å‹å¤±è´¥: ") + last_path + ", é”™è¯¯: " + e.what());
        }
    }
    
    // è®­ç»ƒç»“æŸï¼Œè¾“å‡ºæ€»ç»“
    {
        std::ostringstream oss;
        oss << "========== è®­ç»ƒå®Œæˆ ==========";
        LOG_INFO(oss.str());
    }
    {
        std::ostringstream oss;
        oss << "æœ€ä½³éªŒè¯æŸå¤±: " << std::fixed << std::setprecision(3) << best_val_loss
            << " (ä¿å­˜åœ¨: " << best_path << ")";
        LOG_INFO(oss.str());
    }
    {
        std::ostringstream oss;
        oss << "æœ€åæ¨¡å‹: " << last_path;
        LOG_INFO(oss.str());
    }
}

float evaluate(MTDataset& dataset,
               Transformer model,
               const TransformerConfig& config,
               torch::Device device) {
    // ä½¿ç”¨é…ç½®çš„ä¸­æ–‡åˆ†è¯å™¨è·¯å¾„åŠ è½½åˆ†è¯å™¨ç”¨äºè§£ç 
    auto sp_chn = chinese_tokenizer_load(config.tokenizer_chn);
    
    model->eval();
    torch::NoGradGuard no_grad;
    
    std::vector<std::vector<std::string>> all_candidates;
    std::vector<std::vector<std::vector<std::string>>> all_references;
    
    // è¯„ä¼°æ‰€æœ‰æ•°æ®ï¼ˆæˆ–é™åˆ¶æ•°é‡ï¼‰
    size_t eval_size = dataset.size();
    std::vector<size_t> indices(eval_size);
    std::iota(indices.begin(), indices.end(), 0);
    
    for (size_t i = 0; i < indices.size(); i += config.batch_size) {
        size_t end = std::min(i + config.batch_size, indices.size());
        std::vector<size_t> batch_indices(indices.begin() + i, indices.begin() + end);
        
        // è·å–batchæ•°æ®
        auto batch = dataset.collate_fn(batch_indices, device,
                                       config.padding_idx, config.bos_idx, config.eos_idx,
                                       config.src_vocab_size, config.tgt_vocab_size);
        
        // åˆ›å»ºsrc_mask
        auto src_mask = (batch.src != config.padding_idx).unsqueeze(-2);
        
        // ä½¿ç”¨beam searchè§£ç 
        auto [decode_results, scores] = beam_search(
            model,
            batch.src,
            src_mask,
            config.max_len,
            config.padding_idx,
            config.bos_idx,
            config.eos_idx,
            config.beam_size,
            device
        );
        
        // å¤„ç†è§£ç ç»“æœ
        for (size_t j = 0; j < decode_results.size(); ++j) {
            // å–æœ€ä½³ç»“æœï¼ˆç¬¬ä¸€ä¸ªï¼‰
            if (!decode_results[j].empty()) {
                // å°†token IDè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                std::string translation = sp_chn->decode_ids(decode_results[j][0]);
                all_candidates.push_back(tokenize_chinese(translation));
            } else {
                all_candidates.push_back({});
            }
            
            // å‚è€ƒå¥å­ï¼ˆçœŸå®ç›®æ ‡æ–‡æœ¬ï¼‰
            std::vector<std::vector<std::string>> refs;
            refs.push_back(tokenize_chinese(batch.trg_text[j]));
            all_references.push_back(refs);
        }
        
        // æ˜¾å¼é‡Šæ”¾ batch ä¸­çš„å¼ é‡ï¼ˆå¸®åŠ©é‡Šæ”¾æ˜¾å­˜ï¼‰
        batch.src = torch::Tensor();
        batch.trg = torch::Tensor();
        batch.trg_y = torch::Tensor();
        batch.src_mask = torch::Tensor();
        batch.trg_mask = torch::Tensor();
        
        // å®šæœŸæ¸…ç†CUDAç¼“å­˜ï¼ˆæ¯10ä¸ªbatchæ¸…ç†ä¸€æ¬¡ï¼‰
        if (device.is_cuda() && (i + 1) % 10 == 0) {
           // torch::cuda::empty_cache();  // âœ… å¯ç”¨ï¼šå¼ºåˆ¶é‡Šæ”¾ CUDA ç¼“å­˜
        }
    }
    
    // è®¡ç®—BLEUåˆ†æ•°
    float bleu_score = corpus_bleu(all_candidates, all_references, 4);
    
    // è¯„ä¼°ç»“æŸåæ¸…ç†CUDAç¼“å­˜
    if (device.is_cuda()) {
       // torch::cuda::empty_cache();  // âœ… å¯ç”¨ï¼šå¼ºåˆ¶é‡Šæ”¾ CUDA ç¼“å­˜
    }
    
    return bleu_score;
}


